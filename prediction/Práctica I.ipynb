{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise I: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Projects/genviz/env/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import tree\n",
    "from scipy.stats import uniform, norm, randint as sp_randint\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load balance-scale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data', sep= ',', header= None)\n",
    "dataset = 'balance-scale'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare Stomach Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Grupo',\n",
       " 'Edad',\n",
       " 'Sexo',\n",
       " 'rs6983267_8q24',\n",
       " 'rs1447295_8q24',\n",
       " 'rs4733616_8q24',\n",
       " 'rs7903146_TCF7L2',\n",
       " 'rs12255372_TCF7L2',\n",
       " 'rs2910164_miR146a',\n",
       " ' rs2292832_miR149']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('cancer.csv', sep=',')\n",
    "data.drop('Subject', axis=1, inplace=True)\n",
    "data.drop('HISTOPATOLÃ“GICO', axis=1, inplace=True)\n",
    "dataset = 'cancer'\n",
    "list(data[0:0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify dataset dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  199\n",
      "Dataset shape:  (199, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset length: \", len(data))\n",
    "print(\"Dataset shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, range(1, data.shape[1])]\n",
    "Y = data.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train decision tree with criterion Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100, max_depth=3, min_samples_leaf=5)\n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train decision tree with criterion information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, max_depth=3, min_samples_leaf=5)\n",
    "clf_entropy.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single instance sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'balance-data':\n",
    "    clf_gini.predict([[4, 4, 3, 3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_gini.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "y_pred_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  68.33333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75        37\n",
      "          1       0.59      0.57      0.58        23\n",
      "\n",
      "avg / total       0.68      0.68      0.68        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred)*100)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  68.33333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75        37\n",
      "          1       0.59      0.57      0.58        23\n",
      "\n",
      "avg / total       0.68      0.68      0.68        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_en)*100)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise II: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1)\n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(list(set(y_pred_knn) | set(y_test)))\n",
    "cm = confusion_matrix(y_test, y_pred_knn, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.46      0.55        37\n",
      "          1       0.43      0.65      0.52        23\n",
      "\n",
      "avg / total       0.58      0.53      0.54        60\n",
      "\n",
      "Accuracy:  53.333333333333336 \n",
      "\n",
      "Class  0\n",
      "------------\n",
      "Sensitivity:  45.94594594594595\n",
      "Specificity:  65.21739130434783\n",
      "\n",
      "Class  1\n",
      "------------\n",
      "Sensitivity:  65.21739130434783\n",
      "Specificity:  45.94594594594595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "total = len(y_test)\n",
    "n_cls = len(labels)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_knn)*100, \"\\n\")\n",
    "for i in range(n_cls):\n",
    "    tp = cm[i, i]\n",
    "    fp = sum(cm[j, i] for j in range(n_cls) if i != j)\n",
    "    tn = sum(cm[j, j] for j in range(n_cls) if i != j)\n",
    "    fn = sum(cm[i, j] for j in range(n_cls) if i != j)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    print(\"Class \", labels[i])\n",
    "    print(\"------------\")\n",
    "    print(\"Sensitivity: \", sensitivity*100)\n",
    "    print(\"Specificity: \", specificity*100)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.54      0.62        37\n",
      "          1       0.47      0.65      0.55        23\n",
      "\n",
      "avg / total       0.62      0.58      0.59        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf= RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch and GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 2.93 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.633 (std: 0.027)\n",
      "Parameters: {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 6, 'criterion': 'entropy', 'bootstrap': False, 'max_features': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.626 (std: 0.044)\n",
      "Parameters: {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 3, 'criterion': 'gini', 'bootstrap': True, 'max_features': 4}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.626 (std: 0.085)\n",
      "Parameters: {'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 3, 'criterion': 'entropy', 'bootstrap': True, 'max_features': 8}\n",
      "\n",
      "GridSearchCV took 30.50 seconds for 216 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.669 (std: 0.091)\n",
      "Parameters: {'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True, 'max_features': 3}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.669 (std: 0.060)\n",
      "Parameters: {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 3, 'criterion': 'entropy', 'bootstrap': True, 'max_features': 9}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.669 (std: 0.044)\n",
      "Parameters: {'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 3, 'criterion': 'entropy', 'bootstrap': False, 'max_features': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 9),\n",
    "              \"min_samples_split\": sp_randint(2, 9),\n",
    "              \"min_samples_leaf\": sp_randint(1, 9),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 9],\n",
    "              \"min_samples_split\": [2, 3, 9],\n",
    "              \"min_samples_leaf\": [1, 3, 9],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.78      0.76        37\n",
      "          1       0.62      0.57      0.59        23\n",
      "\n",
      "avg / total       0.70      0.70      0.70        60\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.38      0.47        37\n",
      "          1       0.39      0.65      0.49        23\n",
      "\n",
      "avg / total       0.54      0.48      0.48        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf_gini, open('model', 'wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([11, 11, 1, 1, 1, 11, 1, 1, 1]).reshape(1, -1)\n",
    "rf_clf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
