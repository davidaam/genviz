{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise I: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import tree\n",
    "from scipy.stats import uniform, norm, randint as sp_randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load balance-scale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data', sep= ',', header= None)\n",
    "dataset = 'balance-scale'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare Stomach Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cancer.csv', sep=',')\n",
    "data.drop('Subject', axis=1, inplace=True)\n",
    "data.drop('HISTOPATOLÃ“GICO', axis=1, inplace=True)\n",
    "dataset = 'cancer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify dataset dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  199\n",
      "Dataset shape:  (199, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset length: \", len(data))\n",
    "print(\"Dataset shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, range(1, data.shape[1])]\n",
    "Y = data.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train decision tree with criterion Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100, max_depth=3, min_samples_leaf=5)\n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train decision tree with criterion information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, max_depth=3, min_samples_leaf=5)\n",
    "clf_entropy.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single instance sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'balance-data':\n",
    "    clf_gini.predict([[4, 4, 3, 3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_gini.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "y_pred_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  68.33333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75        37\n",
      "          1       0.59      0.57      0.58        23\n",
      "\n",
      "avg / total       0.68      0.68      0.68        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred)*100)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  68.33333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75        37\n",
      "          1       0.59      0.57      0.58        23\n",
      "\n",
      "avg / total       0.68      0.68      0.68        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_en)*100)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise II: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1)\n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(list(set(y_pred_knn) | set(y_test)))\n",
    "cm = confusion_matrix(y_test, y_pred_knn, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75        37\n",
      "          1       0.59      0.57      0.58        23\n",
      "\n",
      "avg / total       0.68      0.68      0.68        60\n",
      "\n",
      "Accuracy:  53.333333333333336 \n",
      "\n",
      "Class  0\n",
      "------------\n",
      "Sensitivity:  45.94594594594595\n",
      "Specificity:  65.21739130434783\n",
      "\n",
      "Class  1\n",
      "------------\n",
      "Sensitivity:  65.21739130434783\n",
      "Specificity:  45.94594594594595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "total = len(y_test)\n",
    "n_cls = len(labels)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_knn)*100, \"\\n\")\n",
    "for i in range(n_cls):\n",
    "    tp = cm[i, i]\n",
    "    fp = sum(cm[j, i] for j in range(n_cls) if i != j)\n",
    "    tn = sum(cm[j, j] for j in range(n_cls) if i != j)\n",
    "    fn = sum(cm[i, j] for j in range(n_cls) if i != j)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    print(\"Class \", labels[i])\n",
    "    print(\"------------\")\n",
    "    print(\"Sensitivity: \", sensitivity*100)\n",
    "    print(\"Specificity: \", specificity*100)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.73      0.76        37\n",
      "          1       0.62      0.70      0.65        23\n",
      "\n",
      "avg / total       0.73      0.72      0.72        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf= RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch and GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 2.99 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.655 (std: 0.036)\n",
      "Parameters: {'max_features': 2, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 3, 'bootstrap': False}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.626 (std: 0.056)\n",
      "Parameters: {'max_features': 8, 'criterion': 'gini', 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_depth': 3, 'bootstrap': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.619 (std: 0.065)\n",
      "Parameters: {'max_features': 8, 'criterion': 'entropy', 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_depth': None, 'bootstrap': True}\n",
      "\n",
      "GridSearchCV took 22.20 seconds for 216 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.655 (std: 0.028)\n",
      "Parameters: {'max_features': 9, 'criterion': 'entropy', 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_depth': 3, 'bootstrap': True}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.647 (std: 0.077)\n",
      "Parameters: {'max_features': 9, 'criterion': 'entropy', 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_depth': None, 'bootstrap': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.640 (std: 0.033)\n",
      "Parameters: {'max_features': 9, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': None, 'bootstrap': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.640 (std: 0.018)\n",
      "Parameters: {'max_features': 9, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 3, 'bootstrap': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.640 (std: 0.035)\n",
      "Parameters: {'max_features': 9, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_depth': 3, 'bootstrap': False}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.640 (std: 0.035)\n",
      "Parameters: {'max_features': 9, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_depth': 3, 'bootstrap': False}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.640 (std: 0.035)\n",
      "Parameters: {'max_features': 9, 'criterion': 'entropy', 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_depth': 3, 'bootstrap': False}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.640 (std: 0.038)\n",
      "Parameters: {'max_features': 9, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_depth': None, 'bootstrap': False}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.640 (std: 0.038)\n",
      "Parameters: {'max_features': 9, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_depth': None, 'bootstrap': False}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.640 (std: 0.038)\n",
      "Parameters: {'max_features': 9, 'criterion': 'entropy', 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_depth': None, 'bootstrap': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 9),\n",
    "              \"min_samples_split\": sp_randint(2, 9),\n",
    "              \"min_samples_leaf\": sp_randint(1, 9),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 9],\n",
    "              \"min_samples_split\": [2, 3, 9],\n",
    "              \"min_samples_leaf\": [1, 3, 9],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.54      0.62        37\n",
      "          1       0.48      0.70      0.57        23\n",
      "\n",
      "avg / total       0.64      0.60      0.60        60\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.54      0.62        37\n",
      "          1       0.47      0.65      0.55        23\n",
      "\n",
      "avg / total       0.62      0.58      0.59        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_clf, open('model', 'wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([11, 11, 1, 1, 1, 11, 1, 1, 1]).reshape(1, -1)\n",
    "rf_clf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
