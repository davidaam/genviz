{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise I: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Projects/genviz/env/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load balance-scale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data', sep= ',', header= None)\n",
    "dataset = 'balance-scale'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare Stomach Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cancer.csv', sep=',')\n",
    "data.drop('Subject', axis=1, inplace=True)\n",
    "data.drop('HISTOPATOLÃ“GICO', axis=1, inplace=True)\n",
    "dataset = 'cancer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify dataset dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  199\n",
      "Dataset shape:  (199, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset length: \", len(data))\n",
    "print(\"Dataset shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, range(1, data.shape[1])]\n",
    "Y = data.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train decision tree with criterion Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100, max_depth=3, min_samples_leaf=5)\n",
    "clf_gini_gscv = GridSearchCV(estimator=clf_gini, param_grid={\n",
    "    'max_depth': list(range(1, 3, 1)),\n",
    "    'min_samples_leaf': list(range(1, 4, 1)),\n",
    "})\n",
    "clf_gini_rscv = RandomizedSearchCV(estimator=clf_gini, param_distributions={\n",
    "    'max_depth': uniform,\n",
    "    'min_samples_leaf': uniform\n",
    "})\n",
    "clf_gini.fit(X_train, y_train)\n",
    "clf_gini_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train decision tree with criterion information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, max_depth=3, min_samples_leaf=5)\n",
    "clf_entropy_gscv = GridSearchCV(estimator=clf_entropy, param_grid={\n",
    "    'random_state': list(range(0, 201, 1)),\n",
    "    'max_depth': list(range(1, 10, 1)),\n",
    "    'min_samples_leaf': list(range(1, 10, 1)),\n",
    "})\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "clf_entropy_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single instance sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'balance-data':\n",
    "    clf_gini.predict([[4, 4, 3, 3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_gini.predict(X_test)\n",
    "y_pred_gscv = clf_gini_gscv.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "y_pred_en_gscv = clf_entropy_gscv.predict(X_test)\n",
    "y_pred_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  68.33333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75        37\n",
      "          1       0.59      0.57      0.58        23\n",
      "\n",
      "avg / total       0.68      0.68      0.68        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred)*100)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy (Grid search CV) \", accuracy_score(y_test, y_pred_gscv)*100)\n",
    "print(classification_report(y_test, y_pred_gscv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  68.33333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75        37\n",
      "          1       0.59      0.57      0.58        23\n",
      "\n",
      "avg / total       0.68      0.68      0.68        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_en)*100)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy (Grid search CV) \", accuracy_score(y_test, y_pred_en_gscv)*100)\n",
    "print(classification_report(y_test, y_pred_en_gscv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise II: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1)\n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(list(set(y_pred_knn) | set(y_test)))\n",
    "cm = confusion_matrix(y_test, y_pred_knn, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75        37\n",
      "          1       0.59      0.57      0.58        23\n",
      "\n",
      "avg / total       0.68      0.68      0.68        60\n",
      "\n",
      "Accuracy:  53.333333333333336 \n",
      "\n",
      "Class  0\n",
      "------------\n",
      "Sensitivity:  45.94594594594595\n",
      "Specificity:  65.21739130434783\n",
      "\n",
      "Class  1\n",
      "------------\n",
      "Sensitivity:  65.21739130434783\n",
      "Specificity:  45.94594594594595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "total = len(y_test)\n",
    "n_cls = len(labels)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_knn)*100, \"\\n\")\n",
    "for i in range(n_cls):\n",
    "    tp = cm[i, i]\n",
    "    fp = sum(cm[j, i] for j in range(n_cls) if i != j)\n",
    "    tn = sum(cm[j, j] for j in range(n_cls) if i != j)\n",
    "    fn = sum(cm[i, j] for j in range(n_cls) if i != j)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    print(\"Class \", labels[i])\n",
    "    print(\"------------\")\n",
    "    print(\"Sensitivity: \", sensitivity*100)\n",
    "    print(\"Specificity: \", specificity*100)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.68      0.69        37\n",
      "          1       0.52      0.57      0.54        23\n",
      "\n",
      "avg / total       0.64      0.63      0.64        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf= RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
